{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239ef9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('conversations_context_time_series.json') as json_file:\n",
    "    conversations = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6fe9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4\n",
    "eval_name = \"avg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f48a5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "424a2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, accuracy_score, roc_auc_score, recall_score\n",
    "from darts.metrics import ope, mae, mse, mape, mase\n",
    "import json\n",
    "\n",
    "def results_pool(actual_list, actual_ts, future_ts, train_ts):\n",
    "    predicted = [x.values()[0][0] for x in future_ts]\n",
    "    verdict_true = [x[-1]>x[-2] for x in actual_list]\n",
    "    verdict_predicted = [a>x[-2] for a,x in zip(predicted, actual_list)]\n",
    "    precision = precision_score(verdict_true, verdict_predicted)\n",
    "    f1 = f1_score(verdict_true, verdict_predicted)\n",
    "    accuracy = accuracy_score(verdict_true, verdict_predicted)\n",
    "    auc = roc_auc_score(verdict_true, verdict_predicted)\n",
    "    recall = recall_score(verdict_true, verdict_predicted)\n",
    "    mse_err = mse(actual_ts, future_ts, intersect = False)\n",
    "    ope_err = ope(actual_ts, future_ts)\n",
    "    mae_err = mae(actual_ts, future_ts)\n",
    "    mape_err = mape(actual_ts, future_ts)\n",
    "    #mase_err = mase(actual_ts, future_ts, train_ts)\n",
    "    results = {'mse':mean(mse_err), \n",
    "               'ope':mean(ope_err), \n",
    "               'mae':mean(mae_err), \n",
    "               'mape':mean(mape_err),\n",
    "               #'mase':mean(mase_err),\n",
    "               'precision':precision, \n",
    "               'f1':f1, \n",
    "               'accuracy':accuracy, \n",
    "               'auc':auc, \n",
    "               'recall':recall}\n",
    "    with open(f'Results-SotA/NBeatsContext-{steps}-{eval_name}.json', 'w') as file:\n",
    "        json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9edf4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_max = [i['max'] for i in conversations if (0 not in i['max']) and (len(i['max'])>=steps+1)]\n",
    "series_avg = [i['avg'] for i in conversations if (0 not in i['avg']) and (len(i['avg'])>=steps+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "768df9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f1b5560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69a3fab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.130823268 1.0 0.5055667951066781 0.471417151\n",
      "0.0002077292153846154 0.603971215 0.02042109630791462 0.009809837318181818\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "print(min([x for sub in series_max for x in sub]), max([x for sub in series_max for x in sub]), mean([x for sub in series_max for x in sub]), median([x for sub in series_max for x in sub]))\n",
    "print(min([x for sub in series_avg for x in sub]), max([x for sub in series_avg for x in sub]), mean([x for sub in series_avg for x in sub]), median([x for sub in series_avg for x in sub]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20425a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_list_max = [split_sequence(i, steps) for i in series_max]\n",
    "#array_list_avg = [split_sequence(i, steps) for i in series_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d696376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_val_test_split(data, percent1, percent2):\n",
    "    split_place1 = int(percent1*len(data))\n",
    "    split_place2 = int((percent1+percent2)*len(data))\n",
    "    random.shuffle(data)\n",
    "    return data[:split_place1], data[split_place1:split_place2], data[split_place2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc4ea9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_max, val_list_max, test_list_max = train_val_test_split(series_max, 0.6, 0.2)\n",
    "train_list_avg, val_list_avg, test_list_avg = train_val_test_split(series_avg, 0.6, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fe821dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_max = [array(x) for x in train_list_max]\n",
    "train_array_avg = [array(x) for x in train_list_avg]\n",
    "train_max = [x.reshape((x.shape[0], 1, 1)) for x in train_array_max]\n",
    "train_avg = [x.reshape((x.shape[0], 1, 1)) for x in train_array_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7d5fcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1532"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dbc6d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3be1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_array_max = [array(x) for x in val_list_max]\n",
    "val_array_avg = [array(x) for x in val_list_avg]\n",
    "val_max = [x.reshape((x.shape[0], 1, 1)) for x in val_array_max]\n",
    "val_avg = [x.reshape((x.shape[0], 1, 1)) for x in val_array_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a35e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array_max = [array(x) for x in test_list_max]\n",
    "test_array_avg = [array(x) for x in test_list_avg]\n",
    "test_max = [x.reshape((x.shape[0], 1, 1)) for x in test_array_max]\n",
    "test_avg = [x.reshape((x.shape[0], 1, 1)) for x in test_array_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf2b718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NBEATSModel\n",
    "from darts import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5335002",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max_ts = [TimeSeries.from_values(x) for x in test_max]\n",
    "test_avg_ts = [TimeSeries.from_values(x) for x in test_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3877e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_series_avg = [TimeSeries.from_values(x) for x in train_avg]\n",
    "val_series_avg = [TimeSeries.from_values(x) for x in val_avg]\n",
    "predict_series_avg = [x[:-1] for x in test_avg_ts]\n",
    "y_test_avg_ts = [x[-1] for x in test_avg_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf3dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-26 11:26:42,221] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 6055 samples.\n",
      "[2022-02-26 11:26:42,221] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 6055 samples.\n",
      "[2022-02-26 11:26:42,299] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-02-26 11:26:42,299] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c66d3df05a4822ba69cb3cbf5e30df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, validation loss: 0.0012, best val loss: 0.0011\r"
     ]
    }
   ],
   "source": [
    "model_one_step_avg = NBEATSModel(input_chunk_length=steps, output_chunk_length=1)\n",
    "model_one_step_avg.fit(fit_series_avg, val_series=val_series_avg, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02caa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_avg = model_one_step_avg.predict(n=1, series = predict_series_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2459942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pool(test_list_avg, y_test_avg_ts, future_avg, predict_series_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86178d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_name = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36c50209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_series_max = [TimeSeries.from_values(x) for x in train_max]\n",
    "val_series_max = [TimeSeries.from_values(x) for x in val_max]\n",
    "predict_series_max = [x[:-1] for x in test_max_ts]\n",
    "y_test_max_ts = [x[-1] for x in test_max_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8883b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-26 12:50:52,001] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 5880 samples.\n",
      "[2022-02-26 12:50:52,001] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 5880 samples.\n",
      "[2022-02-26 12:50:52,070] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-02-26 12:50:52,070] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbf94d71bac42719202dfff4c8a0fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0123, validation loss: 0.0624, best val loss: 0.0368\r"
     ]
    }
   ],
   "source": [
    "model_one_step_max = NBEATSModel(input_chunk_length=steps, output_chunk_length=1)\n",
    "model_one_step_max.fit(fit_series_max, val_series=val_series_max, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d41ab782",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_max = model_one_step_max.predict(n=1, series = predict_series_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daebfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pool(test_list_max, y_test_max_ts, future_max, predict_series_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15208ae8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
